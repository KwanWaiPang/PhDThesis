
    
<!DOCTYPE html>
<html lang="en-us">

<meta http-equiv="X-UA-Compatible" content="IE=7" />

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <meta name="author" content="Turnitin, LLC" />
    <meta name="keywords" content="" /> 
    <meta name="description" content="" />
<title>Turnitin - Originality Report - Guan Weipeng PhD thesis main (2025.05.09).pdf </title>

<base href="http://www.turnitin.com">
<style type="text/css">
body {
    color: #333;
    background: #C0C7CC;
    padding: 0;
    border: 0;
    font: 13px Verdana, arial, sans-serif;
    margin: 0;
}

form {
    padding: 0;
    margin: 0;
}

body#display {
}

body#bodysource {
    width: 520px;
    background: #F0F4FA;
}

p {
    padding: 10px 18px;
    margin: 0;
}

img {
    border: 0;
    padding: 0;
}

div {
    padding: 0;
    border: 0;
}

iframe {
    border: 0;
    margin: 0;
    padding: 0;
}

strong {
    font-weight: bold;
}

ul {
    padding: 0;
    margin: 0;
    list-style-type: none;
    font-size: 13px;
}

ul li {
    padding: 0;
    margin: 0;
    line-height: 16px;
}

#index span#exclude {
    margin: 0 50px 0 23px;
}

#index a {
    font-size: 11px;
    padding: 0 8px;
}

#index select {
    font-size: 12px;
    border: 1px solid #888;
}

#index input.small {
    margin: 0 0 0 5px;
    width: 30px;
    color: #D10A0A;
    font-weight: bold;
    font-size: 13px;
    border: 1px solid #888;
    vertical-align: baseline;
}

div.links {
    width: 85%;
    margin: 0 auto;
    border-left: 1px solid #888;
    border-right: 1px solid #888;
    padding-top: 8px;
    background: #E8EEF7;
    text-align: left;
}

.links div {
    padding: 5px 13px 10px 20px;
    border-bottom: 1px dotted #888;
}

.links div p {
    padding: 2px 0 0 40px;
}

div#body {
    line-height: 17px;
    width: 85%;
    margin: auto;
    padding: 20px 0;
    background: #fff;
    border-bottom: 1px solid #888;
    border-right: 1px solid #888;
    border-left: 1px solid #888;
    text-align: left;
}

#body p {
    color: #000;
    padding-top: 10 0;
    margin: 0 40px;
}

#actions {
    display: none;
}

a.exclude {
    float: right;
    margin: 0;
    padding: 0;
    position: relative;
    bottom: 20px;
}

/*= SMALL MATCHES POPUP
=== === === === === === === === === === === === === === === === === === === === === === === === === === === === === === */
div#small_matches_prefs {
    visibility: hidden;
    position: absolute;
    top: 0;
    left: 400px;
    background-color: #FFF;
    border: 1px solid #999;
    text-align: right;
}

div#small_matches_prefs p {
    padding: 7px;
}

div#small_matches_prefs li {
    padding: 10px 40px 10px 0;
    border-bottom: 1px solid #999;
    cursor: pointer;
    text-align: left;
}

div#small_matches_prefs li.selected {
    background-color: #87A3C0;
}

div#small_matches_prefs li input {
    text-align: center;
    border: 1px solid #999;
}

div#small_matches_prefs li.disabled input {
    color: #878787;
    background-color: #E6E5E6;
}

div#small_matches_prefs ul label {
    width: 100px;
    text-align: right;
    display: inline-block;
    margin-left: 10px;
    margin-right: 10px;
}
/*= GENERAL
=== === === === === === === === === === === === === === === === === === === === === === === === === === === === === === */

body #top_bar {
    display: none !important;
}

body #index #exclude,
#download_button,
#print_button,
#index .right {
    display: inline-block;
}

body #index {
    width: 85%;
    margin-left: auto;
    margin-right: auto;
    border: 1px solid #999;
    background: #ececec url(new_dynamic/images/22bd7a01a025b8de122259e42762f0a7cb_ug_toolbar_bg.gif) repeat-x center left;
}

#toolbar_wrapper {
    padding-left: 45px;
}

body #top {
    width: 85%;
    background-color: #FFF;
    margin-left: auto;
    margin-right: auto;
    border: 1px solid #999;
    border-bottom: none;
    height: 210px;
}

body #content {
    padding: 10px 60px;
}

body div#prefs {
    display: none;
}

body #top h1 {
    font-size: 20px;
    font-weight: normal;
}

body #top h1 strong {
    font-weight: normal;
}

body #top h1 em {
    font-style: normal;
}


/*body #top h2 {*/
/*    font-size: 20px;*/
/*    font-weight: normal;*/
/*}*/

/*body #top h2 strong {*/
/*    font-weight: normal;*/
/*}*/

/*body #top h2 em {*/
/*    font-style: normal;*/
/*}*/


body #top h2 {
    font-size: 16px;
    font-weight: normal;
}

body #top h2 strong {
    font-weight: normal;
}

body #top h2 em {
    font-style: normal;
}


body #top_body li { /*Paper info li*/
    padding: 0;
    margin: 0px 0px 2px 0px;
    font-size: 10px;
}

#top_body #print_wrapper {
    float: left;
    width: 50%;
}

#top_body .similarity_print_wrapper {
    width: 45%;
    min-width: 283px;
}

#top_body .similarity_box { /*Similarity Box w/ Similarity by Source */
    float: right;
    border: solid 1px #666;
    margin-top: 60px;
    min-width: 350px;
}

#top_body .similarity_box .overall_similarity {
    float: left;
    border-right: solid 1px #666;
}

#top_body .similarity_box .overall_similarity .color_box {
    font-size: 14px;
    min-width: 140px;
}

#top_body .color_box.green {
    background-color: green;
}

#top_body .color_box.blue {
    background-color: blue;
}

#top_body .color_box.yellow {
    background-color: yellow;
}

#top_body .color_box.orange {
    background-color: orange;
}

#top_body .color_box.red {
    background-color: red;
}

#top_body .similarity_box .overall_similarity .similarity_title {
    font-size: 13px;
    font-weight: normal;
    padding: 5px 5px 5px;
    text-align: center;
}

#top_body .similarity_box .overall_similarity .similarity_percent {
    font-size: 25px;
    font-family: georgia, times, serif;
    padding: 5px 0px 15px;
    text-align: center;
}

#top_body .similarity_box .overall_similarity a {
    display: none;
}

#top_body .similarity_box .similarity_by_source {
    float: right;
    font-size: 10px;
}

#top_body .similarity_box .similarity_by_source .similarity_title {
    padding: 6px 0px 0px 10px;
    font-weight: bold;
    text-align: left;
}

#top_body .similarity_box .similarity_by_source dl {
    padding-left: 10px;
    margin: 14px 7px 0px 0px;
}

#top_body .similarity_box .similarity_by_source dt {
    float: left;
    width: 160px;
}

#top_body .similarity_box .similarity_by_source dd {
    float: left;
    margin: 0px;
}


#index span#exclude {
    margin: 0 50px 0 23px;
}

#index a {
    font-size: 11px;
    padding: 0 8px;
}

#index select {
    font-size: 12px;
    border: 1px solid #888;
}

#index input.small {
    margin: 0 0 0 5px;
    width: 30px;
    color: #D10A0A;
    font-weight: bold;
    font-size: 13px;
    border: 1px solid #888;
    vertical-align: baseline;
}

div.links {
    width: 85%;
    margin: 0 auto;
    border-left: 1px solid #888;
    border-right: 1px solid #888;
    padding-top: 8px;
    background: #E8EEF7;
    text-align: left;
}

.links div {
    padding: 5px 13px 10px 20px;
    border-bottom: 1px dotted #888;
}

.links div p {
    padding: 2px 0 0 40px;
}

div#body {
    line-height: 17px;
    width: 85%;
    margin: auto;
    padding: 20px 0;
    background: #fff;
    border-bottom: 1px solid #888;
    border-right: 1px solid #888;
    border-left: 1px solid #888;
    text-align: left;
}

#body p {
    color: #000;
    padding-top: 10 0;
    margin: 0 40px;
}

#actions {
    display: none;
}

button.exclude {
    float: right;
    margin: 0;
    padding: 0;
    border: none;
}

#small_matches_prefs {
    display: none;
}

/*
Copyright (c) 2009, Yahoo! Inc. All rights reserved.
Code licensed under the BSD License:
http://developer.yahoo.net/yui/license.txt
version: 2.7.0
*/
.yui-button{display:-moz-inline-box;display:inline-block;vertical-align:text-bottom;}.yui-button .first-child{display:block;*display:inline-block;}.yui-button button,.yui-button a{display:block;*display:inline-block;border:none;margin:0;}.yui-button button{background-color:transparent;*overflow:visible;cursor:pointer;}.yui-button a{text-decoration:none;}.yui-skin-sam .yui-button{border-width:1px 0;border-style:solid;border-color:#808080;background:url(../images/yui270/build/assets/skins/sam/96b257a32a932f7739d7dab52b38ee8fcb_sprite.png) repeat-x 0 0;margin:auto .25em;}.yui-skin-sam .yui-button .first-child{border-width:0 1px;border-style:solid;border-color:#808080;margin:0 -1px;_margin:0;}.yui-skin-sam .yui-button button,.yui-skin-sam .yui-button a{padding:0 10px;font-size:93%;line-height:2;*line-height:1.7;min-height:2em;*min-height:auto;color:#000;}.yui-skin-sam .yui-button a{*line-height:1.875;*padding-bottom:1px;}.yui-skin-sam .yui-split-button button,.yui-skin-sam .yui-menu-button button{padding-right:20px;background-position:right center;background-repeat:no-repeat;}.yui-skin-sam .yui-menu-button button{background-image:url(yui270/build/button/assets/skins/sam/6305efb37fa05af65c79b58b9d4c1b03cb_menu-button-arrow.png);}.yui-skin-sam .yui-split-button button{background-image:url(yui270/build/button/assets/skins/sam/ced974d5c685e5dfa0a37b824a6b5d48cb_split-button-arrow.png);}.yui-skin-sam .yui-button-focus{border-color:#7D98B8;background-position:0 -1300px;}.yui-skin-sam .yui-button-focus .first-child{border-color:#7D98B8;}.yui-skin-sam .yui-button-focus button,.yui-skin-sam .yui-button-focus a{color:#000;}.yui-skin-sam .yui-split-button-focus button{background-image:url(yui270/build/button/assets/skins/sam/36e66540d2feba76b8991e18b76fe93bcb_split-button-arrow-focus.png);}.yui-skin-sam .yui-button-hover{border-color:#7D98B8;background-position:0 -1300px;}.yui-skin-sam .yui-button-hover .first-child{border-color:#7D98B8;}.yui-skin-sam .yui-button-hover button,.yui-skin-sam .yui-button-hover a{color:#000;}.yui-skin-sam .yui-split-button-hover button{background-image:url(yui270/build/button/assets/skins/sam/36e66540d2feba76b8991e18b76fe93bcb_split-button-arrow-hover.png);}.yui-skin-sam .yui-button-active{border-color:#7D98B8;background-position:0 -1700px;}.yui-skin-sam .yui-button-active .first-child{border-color:#7D98B8;}.yui-skin-sam .yui-button-active button,.yui-skin-sam .yui-button-active a{color:#000;}.yui-skin-sam .yui-split-button-activeoption{border-color:#808080;background-position:0 0;}.yui-skin-sam .yui-split-button-activeoption .first-child{border-color:#808080;}.yui-skin-sam .yui-split-button-activeoption button{background-image:url(yui270/build/button/assets/skins/sam/890272b241c1d8a0db3ce5680b71fab0cb_split-button-arrow-active.png);}.yui-skin-sam .yui-radio-button-checked,.yui-skin-sam .yui-checkbox-button-checked{border-color:#304369;background-position:0 -1400px;}.yui-skin-sam .yui-radio-button-checked .first-child,.yui-skin-sam .yui-checkbox-button-checked .first-child{border-color:#304369;}.yui-skin-sam .yui-radio-button-checked button,.yui-skin-sam .yui-checkbox-button-checked button{color:#fff;}.yui-skin-sam .yui-button-disabled{border-color:#ccc;background-position:0 -1500px;}.yui-skin-sam .yui-button-disabled .first-child{border-color:#ccc;}.yui-skin-sam .yui-button-disabled button,.yui-skin-sam .yui-button-disabled a{color:#A6A6A6;cursor:default;}.yui-skin-sam .yui-menu-button-disabled button{background-image:url(yui270/build/button/assets/skins/sam/4df7235ca027f2546b2a216e59f81fb0cb_menu-button-arrow-disabled.png);}.yui-skin-sam .yui-split-button-disabled button{background-image:url(yui270/build/button/assets/skins/sam/db73dce6da2f5c5f02399c93488ce69ecb_split-button-arrow-disabled.png);}

</style>



</head>

<body onload="">



<link rel="stylesheet" type="text/css" href="/r/build/css/tii/88ee4ccd3555f2b759921fb5d58d83e5cb_container.css" media="all" />




<script type="text/javascript" src="/r/build/js/tii/8b608684a5f4aec1b540987c93498c01cb_tii_anonymous_marking.js"></script>




<script type="text/javascript">

function initAnonymousMarking () {
    // initialize panel.  
    var config = {
            zindex: 4,
            underlay: 'none',
            modal: true,
            visible: false,
            draggable: false,
            close: false,
            fixedcenter: true
    };
    if ($('disable_anonymous_marking')) {
        disableAnonymousMarkingPanel = new IP.widget.Panel($('disable_anonymous_marking'), config);
        if($D.hasClass('disable_anonymous_marking', 'app')) {
            disableAnonymousMarkingPanel.center = function () {
                var nViewportOffset = 20,
                    elementWidth = this.element.offsetWidth,
                    elementHeight = this.element.offsetHeight,
                    viewPortWidth = $D.getViewportWidth(),
                    viewPortHeight = $D.getViewportHeight(),
                    x,
                    y;

                if (elementWidth < viewPortWidth) {
                    x = (viewPortWidth / 2) - (elementWidth / 2) + $D.getDocumentScrollLeft();
                } else {
                    x = nViewportOffset + $D.getDocumentScrollLeft();
                }

				if (browser == 'Internet Explorer') {
					x = 0;
				}
                y = 2 + $D.getDocumentScrollTop();

                this.cfg.setProperty("xy", [parseInt(x, 10), parseInt(y, 10)]);
                this.cfg.refireEvent("iframe");
            };
        }
        disableAnonymousMarkingPanel.render(document.body);
        disableAnonymousMarkingPanel.hideEvent.subscribe(function () { $('anonymous_error').innerHTML = ''; }, false);
        disableAnonymousMarkingPanel.hide();
        Element.show($('disable_anonymous_marking'));
    }
}

function disableAM (data) {
    $('anonymous_title').innerHTML = data.title;
    document.disable_anonymous_marking_form.objectid.value = data.oid;
    disableAnonymousMarkingPanel.show();
}

function checkDisableAM () {
    var form = document.disable_anonymous_marking_form;
    if (form.reason.value.length <= 5) {
        $('anonymous_error').innerHTML = "Please provide a reason for turning anonymous marking off. Your reason must be more than 10 characters in length.";
    }
    else {
        form.submit();
    }
    return;
}

YAHOO.util.Event.onDOMReady(initAnonymousMarking);

</script>

<div id="disable_anonymous_marking" class="app" style="display: none;">
<div class="anonymous_frames">
<form method="post" name="disable_anonymous_marking_form">
    <input type="hidden" name="objectid" value=""/>
    <input type="hidden" name="disable_anonymous_marking" value="1"/> 
    <div class="anonymous_header">
    	<h1>turn off anonymous marking</h1>
		<p>Please state reason for turning off Anonymous Marking for: <span id="anonymous_title"></span><br />
			<strong>Warning: Administrator has access to this information. This setting is permanent.</strong>
        
            </p>
        
    </div>
    <div class="anonymous_body">
        <textarea name="reason" cols="30" rows="3"></textarea>
        <p id="anonymous_error"></p>
    </div>
    <div class="anonymous_footer">
		<div class="anonymous_footer_buttons">
            <span class="submit_form_button"><input type="button" onClick="checkDisableAM();" value="Submit"></span><br>
        	<span class="submit_form_button"><input type="button" value="Cancel" onClick="disableAnonymousMarkingPanel.hide();"></span>
		</div>
    </div>
</form>
</div>
</div>
<div id="actions">
<p>This is a preview of the print version of your report. Please click "print" to continue or "done" to close this window.</p>
<script type="text/javascript" language="javascript">
	var browserName=navigator.appName;
	var browserVer=parseInt(navigator.appVersion);
	if ((navigator.appVersion.indexOf("Mac")!=-1) && (browserName == "Microsoft Internet Explorer")) {
		document.write('<span class="AR10">Type COMMAND-P to print.</span><br><br>');
	} else {
		document.write('<button onclick="window.print();">print</button>&nbsp;&nbsp;');
	}
</script>
<button onclick="window.close();">done</button>
</div>


<!-- ########################### Preferences pop-up ##########################--> 

<div name="top" id="header">

<div id="prefs" role="dialog" style="display:none" aria-labelledby="prefs_link" aria-describedby="prefs_link" aria-owns="prefs_link">
<div class="padding">
<form name="prefs_form" method="post" accept-charset="utf-8">
<script type="text/javascript" language="javascript">
function savePrefs(){
	if (document.prefs_form.changed.value == 1){
		document.prefs_form.submit();
	}else{
        hidePrefsPane();
	}
}

function handlePrefsPaneKeyUp (evt) {
    // first check for IME compositions and ignore
    if (evt.isComposing || evt.keyCode === 229) {
        return;
    }
    if (evt.key === "Escape") {
        evt.preventDefault();
        evt.stopPropagation();
        hidePrefsPane();
    }
}

function showPrefsPane(){
    const prefsDiv = document.getElementById('prefs');
    prefsDiv.style.display='block';
    prefsDiv.addEventListener('keyup', handlePrefsPaneKeyUp);
    document.getElementById('use_colors').focus();
}

function hidePrefsPane(){
    const prefsDiv = document.getElementById('prefs');
    prefsDiv.style.display='none';
    prefsDiv.removeEventListener('keyup', handlePrefsPaneKeyUp);
    document.getElementById('prefs_link').focus();
}

var overlay, $D, $;

function handleSmallMatchesPrefKeyUp (evt) {
    // first check for IME compositions and ignore
    if (evt.isComposing || evt.keyCode === 229) {
        return;
    }
    if (evt.key === "Escape") {
        evt.preventDefault();
        evt.stopPropagation();
        hideSmallMatchExclusions();
    }
}

function showSmallMatchExclusions(left) {
    $D = YAHOO.util.Dom;
    $E = YAHOO.util.Event;
    $ = $D.get;

    $D.setStyle('small_matches_prefs', 'top', $D.getDocumentScrollTop() + 187 + 'px');
    $D.setStyle('small_matches_prefs', 'left', left + 'px');

    $D.setStyle('small_matches_prefs', 'display', 'block');
    $D.setStyle('small_matches_prefs', 'visibility', 'visible');

        // focus the field
    $D.hasClass('exclude_by_percent_row', 'selected') ? $('exclude_by_percent_value').focus() : $('exclude_by_words_value').focus();
    $E.on(window, 'scroll', repositionDialog);



/*
A problem occurs: when the focus moves from the wordcount field to the percentage field
the existing percentage is floored. So even if the value is "correct", it gets incorrect,
because the floored percentage is different from the word count. Especially in bigger texts and smaller matches
this becomes an issue. So, the percentage displayed when updated from the word count should be the rounded one.
only when the input itself is given manually, should this override the exclusionPercent value.

This can be done as long as we use the functions below as actual keyboard handlers, so we can filter between numerical
values entered and other keys (such as tab). Moreover, we could do up and down to increase or decrease the value.

Because we will need to keep a state of the unrounded percentage, it is better to have that percentage value
closed over.

*/

    let rawPercentage = 0;
    function updateExcludePercentage(evt) {
        // prevent symbol composing to interfere, 229 is a special code for the composition key
        if (evt.isComposing || evt.keyCode === 229) {
            return;
        }
        if (evt.key === "Escape") {
            evt.preventDefault();
            evt.stopPropagation();
            hideSmallMatchExclusions();
        }
        else if (/[0-9]/.exec(evt.key) || evt.key === 'Backspace' || evt.key === 'Delete') { //only recalculate when the entered keys represent numbers
            // only when entering or changing the value in the input field, it is clear that the user
            // intended to use this specific exclusion method
            selectSmallExclusionMethod('words');
            const wordCount = this.value;

            rawPercentage = wordCount / 76610 * 100;
            $('exclude_by_percent_value').value = Math.floor(rawPercentage); // only display floored value
        }
    }

    function updateExcludeWordCount(evt) {
        // prevent symbol composing to interfere, 229 is a special code for the composition key
        if (evt.isComposing || evt.keyCode === 229) {
            return;
        }
        if (evt.key === "Escape") {
            evt.preventDefault();
            evt.stopPropagation();
            hideSmallMatchExclusions();
        }
        else if (/[0-9]/.exec(evt.key) || evt.key === 'Backspace' || evt.key === 'Delete') { //only recalculate when the entered keys represent numbers
            // only when entering or changing the value in the input field, it is clear that the user
            // intended to use this specific exclusion method
            selectSmallExclusionMethod('percent');

            const percent = this.value;
            var wordCount = Math.floor((percent/100) * 76610);

            $('exclude_by_words_value').value = wordCount;
        }
    }
    // set to global name space so hideSmallMatchesExclusions can also remove the listeners.
    if (!window.updateExcludePercentage) window.updateExcludePercentage = updateExcludePercentage;
    if (!window.updateExcludeWordCount) window.updateExcludeWordCount = updateExcludeWordCount;

    document.getElementById('small_matches_prefs').addEventListener('keyup', handleSmallMatchesPrefKeyUp);
    document.getElementById('exclude_by_words_value').addEventListener('keyup', updateExcludePercentage);
    document.getElementById('exclude_by_percent_value').addEventListener('keyup', updateExcludeWordCount);

}

function repositionDialog() {
    $D.setStyle('small_matches_prefs', 'top', $D.getDocumentScrollTop() + 187 + 'px');
}

function hideSmallMatchExclusions() {
    document.getElementById('small_matches_prefs').removeEventListener('keyup', handleSmallMatchesPrefKeyUp);
    document.getElementById('exclude_by_words_value').removeEventListener('keyup', updateExcludePercentage);
    document.getElementById('exclude_by_percent_value').removeEventListener('keyup', updateExcludeWordCount);

    $D.setStyle('small_matches_prefs', 'display', 'none');
    $E.removeListener(window, 'scroll', repositionDialog);
    document.getElementById('exclude_small_matches_link').focus();
}

function selectSmallExclusionMethod(enableType) {
    if(enableType == 'words') {
        $('exclude_by_words_value').focus();
        
        $D.addClass('exclude_by_words_row', 'selected');
        $D.removeClass('exclude_by_percent_row', 'selected');
        $D.removeClass('exclude_by_words_row', 'disabled');
        $D.addClass('exclude_by_percent_row', 'disabled');
    }
    else {
        $('exclude_by_percent_value').focus();
        
        $D.removeClass('exclude_by_words_row', 'selected');
        $D.addClass('exclude_by_percent_row', 'selected');
        $D.addClass('exclude_by_words_row', 'disabled');
        $D.removeClass('exclude_by_percent_row', 'disabled');
    }
}

function submitSmallMatchesChange() {
    var excludeBy = $D.hasClass('exclude_by_percent_row', 'selected') ? 'percent' : 'words';
    var excludeValue = excludeBy == 'percent' ? $('exclude_by_percent_value').value : $('exclude_by_words_value').value;
    
    changeSmallMatchExclusion(excludeBy, parseInt(excludeValue), 76610);
}


</script>
<input type="hidden" name="changed" value="0">
        <div class="pref_rows">
                <label for="use_colors">color-code matches:</label>
                <select id="use_colors" name="use_colors" onchange="document.prefs_form.changed.value=1">
                    <option value="1">yes
                    <option value="0">no
                </select>
                <div class="clear"></div>
        </div>
        <div class="pref_rows">
                <label for="def_report_mode">default mode:</label>
                <select id="def_report_mode" name="def_report_mode" onchange="document.prefs_form.changed.value=1">
                    <option value="0">show highest matches together
                    <option value="1">show matches one at a time
                    <option value="2">quickview (classic) report
                </select>
                <div class="clear"></div>
        </div>
        <div class="pref_rows">
                <label for="report_scrolling">auto-navigation:</label>
                <select id="report_scrolling" name="report_scrolling" onchange="document.prefs_form.changed.value=1">
                    <option value="0">jump to next match
                    <option value="1">scroll to next match
                </select>
                <div class="clear"></div>
        </div>
        
        <div id="prefs_confirm">
            <button onClick="savePrefs()" >Save</button>  
            <button onClick="hidePrefsPane();">Cancel</button>
        </div>
</form>
</div>
</div>
</div>
<!-- ########################### END Preferences pop-up  ##########################--> 

<!-- ########################### BEGIN small matches pop-up  ##########################--> 
<div id="small_matches_prefs" role="dialog" aria-labelledby="exclude_small_matches_link" aria-describedby="exclude_small_matches_link" aria-owns="exclude_small_matches_link">
    <form onsubmit="submitSmallMatchesChange(); return false;">
        <ul>
            <li id="exclude_by_words_row" class="selected">
                <label for="exclude_by_words_value">Word Count: </label>
                <input type="text" id="exclude_by_words_value" size="3" value="" onkeyup="updateExcludePercentage"> words
            </li>
            <li id="exclude_by_percent_row" class="disabled">
                <label for="exclude_by_percent_value">Percentage: </label>
                <input type="text" id="exclude_by_percent_value" size="3" value="" max-length="3" onkeyup="updateExcludeWordCount"> %
            </li>
        </ul>
        <p><input type='submit' value="submit"> or <button onclick="hideSmallMatchExclusions()">Cancel</button></p>
    </form>
</div>

<!-- ########################### END small matches pop-up  ##########################-->

<!-- ########################### Top of Report  ##########################--> 
<div id="top">
    <div id="content" role="banner">
    
        <!-- ######### Top Bar  ##########################--> 
        <div id="top_bar">
                <ul id="top_bar_list1">
                      <!-- Preferences --><li><button id="prefs_link" onclick="showPrefsPane(); aria-haspopup="dialog">preferences</button></li>
                </ul>
                <ul id="top_bar_list2">
                      
                </ul>
                <div class="clear"></div>
        </div>   
        <!-- ######### END Top Bar  ##########################--> 
        
        
        <!-- ######### Top Body  ##########################--> 
        <div id="top_body">
        
            <div id="print_wrapper">
                <div class="general_info" role="region" aria-label="Paper Information">
                    <!-- Logo --> 
                    <h1>
                        <span class=""></span>
                        <strong>Turnitin</strong>
                        <em>Originality Report</em>
                     </h1>
                 
                     <!-- Paper Info -->               
                     <ul>
                         <li>Processed on: 10-May-2025 09:48 HKT</li>
                         <li>ID: 2656419329 </li>
                         <li>Word Count: 76610</li>
                         <li>Submitted: 8</li>
                     </ul>
                </div>

                 <!-- Paper Title --> 
                <h2>
                    <strong>Guan Weipeng PhD thesis main (2025.05.09).pdf</strong> 
                    
                    <em>By Weipeng GUAN</em>
                    
                </h2>
            </div>
            
            <div id="similarity_print_wrapper">
                <div class="similarity_box" role="region" aria-labelledby="similarity_index_title" aria-describedby="similarity_index_title">
                    <div class="overall_similarity">
                        <div class="color_box yellow">&nbsp;</div>
                        <div id="similarity_index_title" class="similarity_title">Similarity Index</div>
                        <div class="similarity_percent">48%</div>
                    </div>
                    <div class="similarity_by_source" role="region" aria-labelledby="similarity_by_source_title" aria-describedby="similarity_by_source_title">
                        <div id="similarity_by_source_title" class="similarity_title">Similarity by Source</div>
                        <dl>
                            <dt>Internet&nbsp;Sources:</dt>
                            <dd>41%</dd>
                            <div class="clear"></div>
                            <dt>Publications:</dt>
                            <dd>32%</dd>
                            <div class="clear"></div>
                            <dt>Student&nbsp;Papers:</dt>
                            <dd>8%</dd>
                            <div class="clear"></div>
                        </dl>
                    </div>
                </div>
            </div>
            <div class="clear"></div>
                                 
        </div>
        <!-- ######### END Top Body  ##########################--> 
        
        
    </div>
</div>
<!-- ########################### END Top of Report  ##########################--> 



<!-- ########################### TOOLBAR  ##########################--> 
<div id="index">
	<div id="toolbar_wrapper" role="toolbar">
        
	</div>
</div>
<!-- ########################### END TOOLBAR  ##########################--> 


<div class="links" role="region" aria-label="Match Overview">
    <div role="list">
	<div role="listitem" aria-setsize="146" aria-posinset="1">
	    <p>
	        17% match (Internet from 21-Dec-2023)
	    </p>
        
        
 
	    <p><a href="http://arxiv.org/pdf/2312.11911.pdf" target="_blank" style="color:#D10A0A">http://arxiv.org/pdf/2312.11911.pdf</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="2">
	    <p>
	        7% match (Weipeng Guan, Peiyu Chen, Yuhan Xie, Peng Lu. "PL-EVIO: Robust Monocular Event-Based Visual Inertial Odometry With Point and Line Features", IEEE Transactions on Automation Science and Engineering, 2024)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(806645412,37,'0')" target="_blank" style="color:#287B28">Weipeng Guan, Peiyu Chen, Yuhan Xie, Peng Lu. "PL-EVIO: Robust Monocular Event-Based Visual Inertial Odometry With Point and Line Features", IEEE Transactions on Automation Science and Engineering, 2024</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="3">
	    <p>
	        6% match (Weipeng Guan, Peng Lu. "Monocular Event Visual Inertial Odometry based on Event-corner using Sliding Windows Graph-based Optimization", 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2022)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(783970337,37,'0')" target="_blank" style="color:blue">Weipeng Guan, Peng Lu. "Monocular Event Visual Inertial Odometry based on Event-corner using Sliding Windows Graph-based Optimization", 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2022</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="4">
	    <p>
	        3% match ()
	    </p>
        
        
 
	    <p><a href="http://arxiv.org/abs/2209.12160" target="_blank" style="color:brown">Guan, Weipeng, Chen, Peiyu, Xie, Yuhan, Lu, Peng. "PL-EVIO: Robust Monocular Event-based Visual Inertial Odometry with  Point and Line Features", 2023</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="5">
	    <p>
	        2% match (Internet from 20-Apr-2023)
	    </p>
        
        
 
	    <p><a href="http://export.arxiv.org/pdf/2209.12160" target="_blank" style="color:#B64B01">http://export.arxiv.org/pdf/2209.12160</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="6">
	    <p>
	        1% match (Internet from 08-Nov-2023)
	    </p>
        
        
 
	    <p><a href="https://arxiv.org/pdf/2311.02327.pdf" target="_blank" style="color:#630000">https://arxiv.org/pdf/2311.02327.pdf</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="7">
	    <p>
	        1% match (Internet from 22-Nov-2023)
	    </p>
        
        
 
	    <p><a href="https://export.arxiv.org/pdf/2212.13184" target="_blank" style="color:#0270B6">https://export.arxiv.org/pdf/2212.13184</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="8">
	    <p>
	        1% match (student papers from 02-Nov-2023)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(2736929667,1,'0')" target="_blank" style="color:#330099">Submitted to University of Hong Kong on 2023-11-02</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="9">
	    <p>
	        1% match ()
	    </p>
        
        
 
	    <p><a href="https://www.zora.uzh.ch/id/eprint/187825/1/187825.pdf" target="_blank" style="color:#227967">Rebecq, Henri. "Event cameras: from SLAM to high speed video", 2020</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="10">
	    <p>
	        1% match (Internet from 16-Apr-2024)
	    </p>
        
        
 
	    <p><a href="https://papers.nips.cc/paper_files/paper/2023/file/7ac484b0f1a1719ad5be9aa8c8455fbb-Paper-Conference.pdf" target="_blank" style="color:#CB0099">https://papers.nips.cc/paper_files/paper/2023/file/7ac484b0f1a1719ad5be9aa8c8455fbb-Paper-Conference.pdf</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="11">
	    <p>
	        < 1% match (Internet from 02-Apr-2025)
	    </p>
        
        
 
	    <p><a href="https://arxiv.org/html/2503.22963v1" target="_blank" style="color:#006331">https://arxiv.org/html/2503.22963v1</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="12">
	    <p>
	        < 1% match (Internet from 02-Apr-2025)
	    </p>
        
        
 
	    <p><a href="https://arxiv.org/html/2503.22943v1" target="_blank" style="color:#795AB9">https://arxiv.org/html/2503.22943v1</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="13">
	    <p>
	        < 1% match (Internet from 13-Jul-2024)
	    </p>
        
        
 
	    <p><a href="http://arxiv.org/pdf/2407.07816" target="_blank" style="color:#935F32">http://arxiv.org/pdf/2407.07816</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="14">
	    <p>
	        < 1% match (Internet from 19-Dec-2023)
	    </p>
        
        
 
	    <p><a href="http://arxiv.org/pdf/2312.09800.pdf" target="_blank" style="color:#ce0031">http://arxiv.org/pdf/2312.09800.pdf</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="15">
	    <p>
	        < 1% match (Internet from 12-Dec-2024)
	    </p>
        
        
 
	    <p><a href="https://arxiv.org/html/2412.07080v1" target="_blank" style="color:#866712">https://arxiv.org/html/2412.07080v1</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="16">
	    <p>
	        < 1% match (Internet from 03-Apr-2025)
	    </p>
        
        
 
	    <p><a href="https://arxiv.org/html/2504.00139v1" target="_blank" style="color:#63009c">https://arxiv.org/html/2504.00139v1</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="17">
	    <p>
	        < 1% match ()
	    </p>
        
        
 
	    <p><a href="http://arxiv.org/abs/2212.13184" target="_blank" style="color:#A85503">Chen, Peiyu, Guan, Weipeng, Lu, Peng. "ESVIO: Event-based Stereo Visual Inertial Odometry", 2023</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="18">
	    <p>
	        < 1% match (Internet from 13-Nov-2022)
	    </p>
        
        
 
	    <p><a href="https://arxiv.org/pdf/2001.02319.pdf" target="_blank" style="color:#cc0066">https://arxiv.org/pdf/2001.02319.pdf</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="19">
	    <p>
	        < 1% match ()
	    </p>
        
        
 
	    <p><a href="http://arxiv.org/abs/2304.09793" target="_blank" style="color:#21785B">Huang, Kunping, Zhang, Sen, Zhang, Jing, Tao, Dacheng. "Event-based Simultaneous Localization and Mapping: A Comprehensive  Survey", 2023</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="20">
	    <p>
	        < 1% match (Internet from 03-May-2023)
	    </p>
        
        
 
	    <p><a href="http://export.arxiv.org/pdf/2304.09793" target="_blank" style="color:#336699">http://export.arxiv.org/pdf/2304.09793</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="21">
	    <p>
	        < 1% match (Internet from 23-Nov-2023)
	    </p>
        
        
 
	    <p><a href="https://export.arxiv.org/pdf/2302.08890" target="_blank" style="color:#D10A0A">https://export.arxiv.org/pdf/2302.08890</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="22">
	    <p>
	        < 1% match (student papers from 09-Jul-2023)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(2643432127,1,'0')" target="_blank" style="color:#287B28">Submitted to University of Hong Kong on 2023-07-09</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="23">
	    <p>
	        < 1% match (student papers from 08-Jul-2023)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(2643072402,1,'0')" target="_blank" style="color:blue">Submitted to University of Hong Kong on 2023-07-08</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="24">
	    <p>
	        < 1% match (student papers from 25-Apr-2024)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(2899437209,1,'0')" target="_blank" style="color:brown">Submitted to University of Hong Kong on 2024-04-25</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="25">
	    <p>
	        < 1% match (student papers from 20-Aug-2024)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(2986470549,1,'0')" target="_blank" style="color:#B64B01">Submitted to University of Hong Kong on 2024-08-20</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="26">
	    <p>
	        < 1% match (student papers from 19-Jul-2024)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(2968217315,1,'0')" target="_blank" style="color:#630000">Submitted to University of Hong Kong on 2024-07-19</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="27">
	    <p>
	        < 1% match (student papers from 13-Nov-2023)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(2749613535,1,'0')" target="_blank" style="color:#0270B6">Submitted to University of Hong Kong on 2023-11-13</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="28">
	    <p>
	        < 1% match (student papers from 20-Jun-2024)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(2951452526,1,'0')" target="_blank" style="color:#330099">Submitted to University of Hong Kong on 2024-06-20</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="29">
	    <p>
	        < 1% match (student papers from 29-Aug-2024)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(2992984553,1,'0')" target="_blank" style="color:#227967">Submitted to University of Hong Kong on 2024-08-29</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="30">
	    <p>
	        < 1% match (student papers from 24-Aug-2023)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(2667009570,1,'0')" target="_blank" style="color:#CB0099">Submitted to University of Hong Kong on 2023-08-24</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="31">
	    <p>
	        < 1% match ()
	    </p>
        
        
 
	    <p><a href="https://www.zora.uzh.ch/id/eprint/144555/" target="_blank" style="color:#006331">MÃ¼ggler, Elias. "Event-based Vision for High-Speed Robotics", 2017</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="32">
	    <p>
	        < 1% match (Internet from 26-Dec-2022)
	    </p>
        
        
 
	    <p><a href="https://www.research-collection.ethz.ch/bitstream/handle/20.500.11850/541700/5/ignacio_alzugaray_doctoral_thesis.pdf" target="_blank" style="color:#795AB9">https://www.research-collection.ethz.ch/bitstream/handle/20.500.11850/541700/5/ignacio_alzugaray_doctoral_thesis.pdf</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="33">
	    <p>
	        < 1% match (Internet from 29-Apr-2023)
	    </p>
        
        
 
	    <p><a href="https://www.research-collection.ethz.ch/bitstream/handle/20.500.11850/514829/phd_thesis_ftschopp.pdf?isAllowed=y&sequence=1" target="_blank" style="color:#935F32">https://www.research-collection.ethz.ch/bitstream/handle/20.500.11850/514829/phd_thesis_ftschopp.pdf?isAllowed=y&sequence=1</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="34">
	    <p>
	        < 1% match (Internet from 16-Mar-2023)
	    </p>
        
        
 
	    <p><a href="https://deepai.org/publication/pl-evio-robust-monocular-event-based-visual-inertial-odometry-with-point-and-line-features" target="_blank" style="color:#ce0031">https://deepai.org/publication/pl-evio-robust-monocular-event-based-visual-inertial-odometry-with-point-and-line-features</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="35">
	    <p>
	        < 1% match (student papers from 15-May-2023)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(2604179144,1,'0')" target="_blank" style="color:#866712">Submitted to University of Sydney on 2023-05-15</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="36">
	    <p>
	        < 1% match (student papers from 05-May-2023)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(2594592277,1,'0')" target="_blank" style="color:#63009c">Submitted to University of Sydney on 2023-05-05</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="37">
	    <p>
	        < 1% match (student papers from 29-Apr-2024)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(2903074800,1,'0')" target="_blank" style="color:#A85503">Submitted to University of Sydney on 2024-04-29</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="38">
	    <p>
	        < 1% match (Mohsen Shahraki, Ahmed Elamin, Ahmed El-Rabbany. "Event-Based Visual Simultaneous Localization and Mapping (EVSLAM) Techniques: State of the Art and Future Directions", Journal of Sensor and Actuator Networks, 2025)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(831782646,37,'0')" target="_blank" style="color:#cc0066">Mohsen Shahraki, Ahmed Elamin, Ahmed El-Rabbany. "Event-Based Visual Simultaneous Localization and Mapping (EVSLAM) Techniques: State of the Art and Future Directions", Journal of Sensor and Actuator Networks, 2025</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="39">
	    <p>
	        < 1% match (Internet from 14-Dec-2022)
	    </p>
        
        
 
	    <p><a href="https://digital.library.adelaide.edu.au/dspace/bitstream/2440/136406/1/Liu2022_PhD.pdf" target="_blank" style="color:#21785B">https://digital.library.adelaide.edu.au/dspace/bitstream/2440/136406/1/Liu2022_PhD.pdf</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="40">
	    <p>
	        < 1% match (Internet from 03-Apr-2023)
	    </p>
        
        
 
	    <p><a href="https://ceur-ws.org/Vol-3248/paper12.pdf" target="_blank" style="color:#336699">https://ceur-ws.org/Vol-3248/paper12.pdf</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="41">
	    <p>
	        < 1% match (Wanting Xu, Xin Peng, Laurent Kneip. "Tight Fusion of Events and Inertial Measurements for Direct Velocity Estimation", IEEE Transactions on Robotics, 2023)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(809107193,37,'0')" target="_blank" style="color:#D10A0A">Wanting Xu, Xin Peng, Laurent Kneip. "Tight Fusion of Events and Inertial Measurements for Direct Velocity Estimation", IEEE Transactions on Robotics, 2023</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="42">
	    <p>
	        < 1% match (Lipson, Lahav. "Fast and Robust 3D Reconstruction.", Princeton University)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(834377683,917,'0')" target="_blank" style="color:#287B28">Lipson, Lahav. "Fast and Robust 3D Reconstruction.", Princeton University</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="43">
	    <p>
	        < 1% match (Internet from 14-Dec-2024)
	    </p>
        
        
 
	    <p><a href="https://d-nb.info/1350826243/34" target="_blank" style="color:blue">https://d-nb.info/1350826243/34</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="44">
	    <p>
	        < 1% match (Internet from 22-Feb-2025)
	    </p>
        
        
 
	    <p><a href="https://rpg.ifi.uzh.ch/docs/IROS24_Pellerito.pdf" target="_blank" style="color:brown">https://rpg.ifi.uzh.ch/docs/IROS24_Pellerito.pdf</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="45">
	    <p>
	        < 1% match (Internet from 19-Nov-2023)
	    </p>
        
        
 
	    <p><a href="https://pure.rug.nl/ws/files/830806072/Complete_thesis.pdf" target="_blank" style="color:#B64B01">https://pure.rug.nl/ws/files/830806072/Complete_thesis.pdf</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="46">
	    <p>
	        < 1% match (Peiyu Chen, Weipeng Guan, Peng Lu. "ESVIO: Event-Based Stereo Visual Inertial Odometry", IEEE Robotics and Automation Letters, 2023)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(794918886,37,'0')" target="_blank" style="color:#630000">Peiyu Chen, Weipeng Guan, Peng Lu. "ESVIO: Event-Based Stereo Visual Inertial Odometry", IEEE Robotics and Automation Letters, 2023</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="47">
	    <p>
	        < 1% match (Internet from 21-Jan-2025)
	    </p>
        
        
 
	    <p><a href="https://upcommons.upc.edu/bitstream/handle/2117/422144/Event-based_egomotion_estimation_Sergi_Sanchez_Orvay_TFG.pdf?isAllowed=y&sequence=3" target="_blank" style="color:#0270B6">https://upcommons.upc.edu/bitstream/handle/2117/422144/Event-based_egomotion_estimation_Sergi_Sanchez_Orvay_TFG.pdf?isAllowed=y&sequence=3</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="48">
	    <p>
	        < 1% match (Yi-Fan Zuo, Wanting Xu, Xia Wang, Yifu Wang, Laurent Kneip. "Cross-Modal Semi-Dense 6-DoF Tracking of an Event Camera in Challenging Conditions", IEEE Transactions on Robotics, 2024)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(813615870,37,'0')" target="_blank" style="color:#330099">Yi-Fan Zuo, Wanting Xu, Xia Wang, Yifu Wang, Laurent Kneip. "Cross-Modal Semi-Dense 6-DoF Tracking of an Event Camera in Challenging Conditions", IEEE Transactions on Robotics, 2024</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="49">
	    <p>
	        < 1% match (Yuzhen Wu, Lingxue Wang, Lian Zhang, Mingkun Chen, Wenqu Zhao, Dezhi Zheng, Yi Cai. "Monocular thermal SLAM with neural radiance fields for 3D scene reconstruction", Neurocomputing, 2025)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(830548536,37,'0')" target="_blank" style="color:#227967">Yuzhen Wu, Lingxue Wang, Lian Zhang, Mingkun Chen, Wenqu Zhao, Dezhi Zheng, Yi Cai. "Monocular thermal SLAM with neural radiance fields for 3D scene reconstruction", Neurocomputing, 2025</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="50">
	    <p>
	        < 1% match (student papers from 02-Sep-2024)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(2996253253,1,'0')" target="_blank" style="color:#CB0099">Submitted to University of Oklahoma on 2024-09-02</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="51">
	    <p>
	        < 1% match (Internet from 16-Mar-2024)
	    </p>
        
        
 
	    <p><a href="https://iris.polito.it/retrieve/1b67f5b0-c083-43fb-ac95-9cc9827596fc/thesis_mirco_planamente.pdf" target="_blank" style="color:#006331">https://iris.polito.it/retrieve/1b67f5b0-c083-43fb-ac95-9cc9827596fc/thesis_mirco_planamente.pdf</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="52">
	    <p>
	        < 1% match (student papers from 07-Feb-2025)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(3148146442,1,'0')" target="_blank" style="color:#795AB9">Submitted to Rochester Institute of Technology on 2025-02-07</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="53">
	    <p>
	        < 1% match (Teed, Zachary. "Optimization Inspired Neural Networks for Multiview 3D Reconstruction", Princeton University, 2022)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(780463566,917,'0')" target="_blank" style="color:#935F32">Teed, Zachary. "Optimization Inspired Neural Networks for Multiview 3D Reconstruction", Princeton University, 2022</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="54">
	    <p>
	        < 1% match (Lee, Connor Tinghan. "Learning-Based Perception for Robotics in Suboptimal Data Landscapes", California Institute of Technology, 2024)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(828484416,917,'0')" target="_blank" style="color:#ce0031">Lee, Connor Tinghan. "Learning-Based Perception for Robotics in Suboptimal Data Landscapes", California Institute of Technology, 2024</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="55">
	    <p>
	        < 1% match (SarÄ±kamÄ±Å, Furkan Aykut. "Utilization of Gaussian Splatting in Visual Slam", Middle East Technical University (Turkey))
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(837679086,917,'0')" target="_blank" style="color:#866712">SarÄ±kamÄ±Å, Furkan Aykut. "Utilization of Gaussian Splatting in Visual Slam", Middle East Technical University (Turkey)</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="56">
	    <p>
	        < 1% match (QueirÃ³s Arcanjo, Bruno Rafael. "Efficient Visual Place Recognition in Changing Environments for Resource-Constrained Platforms", University of Essex (United Kingdom))
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(837681327,917,'0')" target="_blank" style="color:#63009c">QueirÃ³s Arcanjo, Bruno Rafael. "Efficient Visual Place Recognition in Changing Environments for Resource-Constrained Platforms", University of Essex (United Kingdom)</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="57">
	    <p>
	        < 1% match (Guillermo Gallego, Tobi Delbruck, Garrick Michael Orchard, Chiara Bartolozzi et al. "Event-based Vision: A Survey", IEEE Transactions on Pattern Analysis and Machine Intelligence, 2020)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(665259919,37,'0')" target="_blank" style="color:#A85503">Guillermo Gallego, Tobi Delbruck, Garrick Michael Orchard, Chiara Bartolozzi et al. "Event-based Vision: A Survey", IEEE Transactions on Pattern Analysis and Machine Intelligence, 2020</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="58">
	    <p>
	        < 1% match (student papers from 22-Sep-2022)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(706591085,2,'0')" target="_blank" style="color:#cc0066">Submitted to University of Birmingham  on 2022-09-22</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="59">
	    <p>
	        < 1% match (Zhu, Shengjie. "Structure and Motion From Depth and Correspondence Models", Michigan State University)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(837681915,917,'0')" target="_blank" style="color:#21785B">Zhu, Shengjie. "Structure and Motion From Depth and Correspondence Models", Michigan State University</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="60">
	    <p>
	        < 1% match (Internet from 26-Mar-2024)
	    </p>
        
        
 
	    <p><a href="https://www.biblio.univ-evry.fr/theses/2023/2023UPAST119.pdf" target="_blank" style="color:#336699">https://www.biblio.univ-evry.fr/theses/2023/2023UPAST119.pdf</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="61">
	    <p>
	        < 1% match (Ninghui Xu, Lihui Wang, Zhiting Yao, Takayuki Okatani. "METS: Motion-Encoded Time-Surface for Event-Based High-Speed Pose Tracking", International Journal of Computer Vision, 2025)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(834175788,37,'0')" target="_blank" style="color:#D10A0A">Ninghui Xu, Lihui Wang, Zhiting Yao, Takayuki Okatani. "METS: Motion-Encoded Time-Surface for Event-Based High-Speed Pose Tracking", International Journal of Computer Vision, 2025</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="62">
	    <p>
	        < 1% match ("Computer Vision â ECCV 2018", Springer Science and Business Media LLC, 2018)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(616812302,37,'0')" target="_blank" style="color:#287B28">"Computer Vision â ECCV 2018", Springer Science and Business Media LLC, 2018</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="63">
	    <p>
	        < 1% match (Jiafeng Huang, Shengjie Zhao, Tianjun Zhang, Lin Zhang. "MC-VEO: A Visual-Event Odometry With Accurate 6-DoF Motion Compensation", IEEE Transactions on Intelligent Vehicles, 2024)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(805677014,37,'0')" target="_blank" style="color:blue">Jiafeng Huang, Shengjie Zhao, Tianjun Zhang, Lin Zhang. "MC-VEO: A Visual-Event Odometry With Accurate 6-DoF Motion Compensation", IEEE Transactions on Intelligent Vehicles, 2024</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="64">
	    <p>
	        < 1% match (student papers from 19-Sep-2024)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(231235109,3599,'0')" target="_blank" style="color:brown">Submitted to UCL on 2024-09-19</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="65">
	    <p>
	        < 1% match (Internet from 18-Feb-2025)
	    </p>
        
        
 
	    <p><a href="https://repository.essex.ac.uk/31706/1/University_of_Essex_PhD_THESIS_Tuo.pdf" target="_blank" style="color:#B64B01">https://repository.essex.ac.uk/31706/1/University_of_Essex_PhD_THESIS_Tuo.pdf</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="66">
	    <p>
	        < 1% match (Robert GuamÃ¡n-Rivera, Jose Delpiano, Rodrigo Verschae. "Event-based optical flow: Method categorisation and review of techniques that leverage deep learning", Neurocomputing, 2025)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(836421072,37,'0')" target="_blank" style="color:#630000">Robert GuamÃ¡n-Rivera, Jose Delpiano, Rodrigo Verschae. "Event-based optical flow: Method categorisation and review of techniques that leverage deep learning", Neurocomputing, 2025</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="67">
	    <p>
	        < 1% match (Zhe Liu, Dianxi Shi, Ruihao Li, Shaowu Yang. "ESVIO: Event-Based Stereo Visual-Inertial Odometry", Sensors, 2023)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(787526723,37,'0')" target="_blank" style="color:#0270B6">Zhe Liu, Dianxi Shi, Ruihao Li, Shaowu Yang. "ESVIO: Event-Based Stereo Visual-Inertial Odometry", Sensors, 2023</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="68">
	    <p>
	        < 1% match (Internet from 05-Sep-2024)
	    </p>
        
        
 
	    <p><a href="https://digibug.ugr.es/bitstream/handle/10481/93842/3656469.pdf?isAllowed=y&sequence=1" target="_blank" style="color:#330099">https://digibug.ugr.es/bitstream/handle/10481/93842/3656469.pdf?isAllowed=y&sequence=1</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="69">
	    <p>
	        < 1% match (Internet from 05-May-2025)
	    </p>
        
        
 
	    <p><a href="https://digibug.ugr.es/bitstream/handle/10481/96383/Neuromorphic_Perception_and_Navigation_for_Mobile_Robots__A_Review.pdf?isAllowed=y&sequence=1" target="_blank" style="color:#227967">https://digibug.ugr.es/bitstream/handle/10481/96383/Neuromorphic_Perception_and_Navigation_for_Mobile_Robots__A_Review.pdf?isAllowed=y&sequence=1</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="70">
	    <p>
	        < 1% match (Nir, Jagatpreet Singh. "Low Contrast Visual Sensing and Inertial Navigation in GPS Denied Environments", Northeastern University, 2024)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(826424765,917,'0')" target="_blank" style="color:#CB0099">Nir, Jagatpreet Singh. "Low Contrast Visual Sensing and Inertial Navigation in GPS Denied Environments", Northeastern University, 2024</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="71">
	    <p>
	        < 1% match (Internet from 09-May-2025)
	    </p>
        
        
 
	    <p><a href="https://cslinzhang.github.io/home/icmr2025/yang.pdf" target="_blank" style="color:#006331">https://cslinzhang.github.io/home/icmr2025/yang.pdf</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="72">
	    <p>
	        < 1% match (Internet from 13-Dec-2024)
	    </p>
        
        
 
	    <p><a href="https://www.roboticsproceedings.org/rss20/p088.pdf" target="_blank" style="color:#795AB9">https://www.roboticsproceedings.org/rss20/p088.pdf</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="73">
	    <p>
	        < 1% match (Shifan Zhu, Zhipeng Tang, Michael Yang, Erik Learned-Miller, Donghyun Kim. "Event Camera-Based Visual Odometry for Dynamic Motion Tracking of a Legged Robot Using Adaptive Time Surface", 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2023)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(811422539,37,'0')" target="_blank" style="color:#935F32">Shifan Zhu, Zhipeng Tang, Michael Yang, Erik Learned-Miller, Donghyun Kim. "Event Camera-Based Visual Odometry for Dynamic Motion Tracking of a Legged Robot Using Adaptive Time Surface", 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2023</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="74">
	    <p>
	        < 1% match (Internet from 16-Feb-2023)
	    </p>
        
        
 
	    <p><a href="https://www.politesi.polimi.it/bitstream/10589/187047/1/phd-thesis-cannici.pdf" target="_blank" style="color:#ce0031">https://www.politesi.polimi.it/bitstream/10589/187047/1/phd-thesis-cannici.pdf</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="75">
	    <p>
	        < 1% match (Rebello, Jason Joseph. "Unlocking Dynamic Cameras for Visual Navigation.", University of Toronto (Canada), 2023)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(802775604,917,'0')" target="_blank" style="color:#866712">Rebello, Jason Joseph. "Unlocking Dynamic Cameras for Visual Navigation.", University of Toronto (Canada), 2023</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="76">
	    <p>
	        < 1% match (Zhu, Chenqi. "Inertially Constrained Ruled Surfaces for Visual Odometry", University of Maryland, College Park, 2025)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(833065763,917,'0')" target="_blank" style="color:#63009c">Zhu, Chenqi. "Inertially Constrained Ruled Surfaces for Visual Odometry", University of Maryland, College Park, 2025</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="77">
	    <p>
	        < 1% match (JeremÃ­as Gaia, Eugenio Orosco, Francisco Rossomando, Carlos Soria. "Mapping the Landscape of SLAM Research: A Review", IEEE Latin America Transactions, 2023)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(808064002,37,'0')" target="_blank" style="color:#A85503">JeremÃ­as Gaia, Eugenio Orosco, Francisco Rossomando, Carlos Soria. "Mapping the Landscape of SLAM Research: A Review", IEEE Latin America Transactions, 2023</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="78">
	    <p>
	        < 1% match ("Computer Vision â ECCV 2016", Springer Science and Business Media LLC, 2016)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(668936307,37,'0')" target="_blank" style="color:#cc0066">"Computer Vision â ECCV 2016", Springer Science and Business Media LLC, 2016</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="79">
	    <p>
	        < 1% match (Jagannatha Sanket, Nitin. "Active Vision Based Embodied-AI Design for Nano-UAV Autonomy", University of Maryland, College Park, 2021)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(759042416,917,'0')" target="_blank" style="color:#21785B">Jagannatha Sanket, Nitin. "Active Vision Based Embodied-AI Design for Nano-UAV Autonomy", University of Maryland, College Park, 2021</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="80">
	    <p>
	        < 1% match (Jiang, Zhongyu. "Towards Robust and Effective Human Pose Estimation and Generation", University of Washington)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(837683953,917,'0')" target="_blank" style="color:#336699">Jiang, Zhongyu. "Towards Robust and Effective Human Pose Estimation and Generation", University of Washington</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="81">
	    <p>
	        < 1% match (KÄ±lÄ±Ã§, Onur Selim. "Utilization of Event Based Cameras for Video Frame Interpolation", Middle East Technical University (Turkey), 2024)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(828560973,917,'0')" target="_blank" style="color:#D10A0A">KÄ±lÄ±Ã§, Onur Selim. "Utilization of Event Based Cameras for Video Frame Interpolation", Middle East Technical University (Turkey), 2024</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="82">
	    <p>
	        < 1% match ("Intelligent Robotics and Applications", Springer Science and Business Media LLC, 2023)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(835660663,37,'0')" target="_blank" style="color:#287B28">"Intelligent Robotics and Applications", Springer Science and Business Media LLC, 2023</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="83">
	    <p>
	        < 1% match (Internet from 16-Nov-2024)
	    </p>
        
        
 
	    <p><a href="https://www.preprints.org/manuscript/202405.1094/v1" target="_blank" style="color:blue">https://www.preprints.org/manuscript/202405.1094/v1</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="84">
	    <p>
	        < 1% match (Benny Dai, Cedric Le Gentil, Teresa Vidal-Calleja. "A Tightly-Coupled Event-Inertial Odometry using Exponential Decay and Linear Preintegrated Measurements", 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2022)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(783970615,37,'0')" target="_blank" style="color:brown">Benny Dai, Cedric Le Gentil, Teresa Vidal-Calleja. "A Tightly-Coupled Event-Inertial Odometry using Exponential Decay and Linear Preintegrated Measurements", 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2022</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="85">
	    <p>
	        < 1% match (Bo Xu, Xin Li, Jingrong Wang, Chau Yuen, Jiancheng Li. "PVI-DSO: Leveraging Planar Regularities for Direct Sparse Visual-Inertial Odometry", IEEE Sensors Journal, 2023)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(799031774,37,'0')" target="_blank" style="color:#B64B01">Bo Xu, Xin Li, Jingrong Wang, Chau Yuen, Jiancheng Li. "PVI-DSO: Leveraging Planar Regularities for Direct Sparse Visual-Inertial Odometry", IEEE Sensors Journal, 2023</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="86">
	    <p>
	        < 1% match (Xingdong Sheng, Shijie Mao, Yichao Yan, Xiaokang Yang. "Review on SLAM algorithms for Augmented Reality", Displays, 2024)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(827829352,37,'0')" target="_blank" style="color:#630000">Xingdong Sheng, Shijie Mao, Yichao Yan, Xiaokang Yang. "Review on SLAM algorithms for Augmented Reality", Displays, 2024</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="87">
	    <p>
	        < 1% match ("Computer Vision â ECCV 2022", Springer Science and Business Media LLC, 2022)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(779920922,37,'0')" target="_blank" style="color:#0270B6">"Computer Vision â ECCV 2022", Springer Science and Business Media LLC, 2022</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="88">
	    <p>
	        < 1% match (student papers from 28-Feb-2025)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(797722455,2,'0')" target="_blank" style="color:#330099">Submitted to Imperial College of Science, Technology and Medicine   on 2025-02-28</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="89">
	    <p>
	        < 1% match (student papers from 16-Sep-2022)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(706344327,2,'0')" target="_blank" style="color:#227967">Submitted to Imperial College of Science, Technology and Medicine   on 2022-09-16</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="90">
	    <p>
	        < 1% match (Cedric Le Gentil, Ignacio Alzugaray, Teresa Vidal-Calleja. "Continuous-Time Gaussian Process Motion-Compensation for Event-Vision Pattern Tracking with Distance Fields", 2023 IEEE International Conference on Robotics and Automation (ICRA), 2023)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(799840432,37,'0')" target="_blank" style="color:#CB0099">Cedric Le Gentil, Ignacio Alzugaray, Teresa Vidal-Calleja. "Continuous-Time Gaussian Process Motion-Compensation for Event-Vision Pattern Tracking with Distance Fields", 2023 IEEE International Conference on Robotics and Automation (ICRA), 2023</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="91">
	    <p>
	        < 1% match (Internet from 15-Feb-2024)
	    </p>
        
        
 
	    <p><a href="https://khazna.ku.ac.ae/ws/portalfiles/portal/19097820/file" target="_blank" style="color:#006331">https://khazna.ku.ac.ae/ws/portalfiles/portal/19097820/file</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="92">
	    <p>
	        < 1% match (Weiqiang Zhao, Hang Sun, Xinyu Zhang, Yijin Xiong. "Visual SLAM Combining Lines and Structural Regularities: Towards Robust Localization", IEEE Transactions on Intelligent Vehicles, 2023)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(803131079,37,'0')" target="_blank" style="color:#795AB9">Weiqiang Zhao, Hang Sun, Xinyu Zhang, Yijin Xiong. "Visual SLAM Combining Lines and Structural Regularities: Towards Robust Localization", IEEE Transactions on Intelligent Vehicles, 2023</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="93">
	    <p>
	        < 1% match ("Advances in Guidance, Navigation and Control", Springer Science and Business Media LLC, 2025)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(834020103,37,'0')" target="_blank" style="color:#935F32">"Advances in Guidance, Navigation and Control", Springer Science and Business Media LLC, 2025</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="94">
	    <p>
	        < 1% match (Dong, Xingshuai. "Visual Guidance for Unmanned Aerial Vehicles With Deep Learning.", University of New South Wales (Australia))
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(834393206,917,'0')" target="_blank" style="color:#ce0031">Dong, Xingshuai. "Visual Guidance for Unmanned Aerial Vehicles With Deep Learning.", University of New South Wales (Australia)</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="95">
	    <p>
	        < 1% match (Internet from 07-Jul-2023)
	    </p>
        
        
 
	    <p><a href="https://www.arxiv-vanity.com/papers/2212.13184/" target="_blank" style="color:#866712">https://www.arxiv-vanity.com/papers/2212.13184/</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="96">
	    <p>
	        < 1% match (student papers from 04-May-2023)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(2593316042,1,'0')" target="_blank" style="color:#63009c">Submitted to Khalifa University of Science Technology and Research on 2023-05-04</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="97">
	    <p>
	        < 1% match (Zhong, Yuanyi. "Sample-Efficient Learning With Self-Supervision", University of Illinois at Urbana-Champaign)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(837681468,917,'0')" target="_blank" style="color:#A85503">Zhong, Yuanyi. "Sample-Efficient Learning With Self-Supervision", University of Illinois at Urbana-Champaign</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="98">
	    <p>
	        < 1% match ("Artificial Neural Networks and Machine Learning â ICANN 2024", Springer Science and Business Media LLC, 2024)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(826109720,37,'0')" target="_blank" style="color:#cc0066">"Artificial Neural Networks and Machine Learning â ICANN 2024", Springer Science and Business Media LLC, 2024</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="99">
	    <p>
	        < 1% match (Grama Satyanarayana, Srivatsa. "Monocular Event Camera Odometry Using Deep Learning", University of Washington, 2025)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(833068325,917,'0')" target="_blank" style="color:#21785B">Grama Satyanarayana, Srivatsa. "Monocular Event Camera Odometry Using Deep Learning", University of Washington, 2025</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="100">
	    <p>
	        < 1% match (Yasin Almalioglu, Mehmet Turan, Muhamad Risqi U. Saputra, Pedro P.B. de GusmÃ£o, Andrew Markham, Niki Trigoni. "SelfVIO: Self-supervised deep monocular VisualâInertial Odometry and depth estimation", Neural Networks, 2022)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(758144645,37,'0')" target="_blank" style="color:#336699">Yasin Almalioglu, Mehmet Turan, Muhamad Risqi U. Saputra, Pedro P.B. de GusmÃ£o, Andrew Markham, Niki Trigoni. "SelfVIO: Self-supervised deep monocular VisualâInertial Odometry and depth estimation", Neural Networks, 2022</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="101">
	    <p>
	        < 1% match (Zhao, Qingqing. "Building Human-Like Embodied Agents from Humans", Stanford University)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(837685282,917,'0')" target="_blank" style="color:#D10A0A">Zhao, Qingqing. "Building Human-Like Embodied Agents from Humans", Stanford University</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="102">
	    <p>
	        < 1% match (Feng, Qiaojun. "3D Semantic Scene Understanding and Reconstruction", University of California, San Diego, 2024)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(816376540,917,'0')" target="_blank" style="color:#287B28">Feng, Qiaojun. "3D Semantic Scene Understanding and Reconstruction", University of California, San Diego, 2024</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="103">
	    <p>
	        < 1% match (Peijing Li, Hexiong Yao, Zhiqiang Dai, Xiangwei Zhu. "Asynchronous Visual-Inertial Odometry for Event Cameras", The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, 2024)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(827549096,37,'0')" target="_blank" style="color:blue">Peijing Li, Hexiong Yao, Zhiqiang Dai, Xiangwei Zhu. "Asynchronous Visual-Inertial Odometry for Event Cameras", The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, 2024</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="104">
	    <p>
	        < 1% match (Internet from 08-Apr-2025)
	    </p>
        
        
 
	    <p><a href="https://researchrepository.universityofgalway.ie/server/api/core/bitstreams/4108a3ce-5274-4f30-bb87-cf5f6b3471e7/content" target="_blank" style="color:brown">https://researchrepository.universityofgalway.ie/server/api/core/bitstreams/4108a3ce-5274-4f30-bb87-cf5f6b3471e7/content</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="105">
	    <p>
	        < 1% match (Internet from 01-Apr-2025)
	    </p>
        
        
 
	    <p><a href="https://ses.library.usyd.edu.au/bitstream/handle/2123/33750/Event_based_3D_Reconstruction__Innovative_Event_Representation_Methods.pdf?isAllowed=y&sequence=6" target="_blank" style="color:#B64B01">https://ses.library.usyd.edu.au/bitstream/handle/2123/33750/Event_based_3D_Reconstruction__Innovative_Event_Representation_Methods.pdf?isAllowed=y&sequence=6</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="106">
	    <p>
	        < 1% match (Internet from 19-Aug-2023)
	    </p>
        
        
 
	    <p><a href="https://uwspace.uwaterloo.ca/bitstream/handle/10012/18293/Azzi_Charbel.pdf?isAllowed=y&sequence=1" target="_blank" style="color:#630000">https://uwspace.uwaterloo.ca/bitstream/handle/10012/18293/Azzi_Charbel.pdf?isAllowed=y&sequence=1</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="107">
	    <p>
	        < 1% match ("Computer Vision â ECCV 2022 Workshops", Springer Science and Business Media LLC, 2023)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(787731359,37,'0')" target="_blank" style="color:#0270B6">"Computer Vision â ECCV 2022 Workshops", Springer Science and Business Media LLC, 2023</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="108">
	    <p>
	        < 1% match (Zhang, Yanyu. "Towards AI-Aided Multi-User AR: Cooperative Visual-Inertial Odometry Enhanced by Point-Line Features and Neural Radiance Fields", University of California, Riverside)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(837682892,917,'0')" target="_blank" style="color:#330099">Zhang, Yanyu. "Towards AI-Aided Multi-User AR: Cooperative Visual-Inertial Odometry Enhanced by Point-Line Features and Neural Radiance Fields", University of California, Riverside</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="109">
	    <p>
	        < 1% match (Le Gentil, Cedric. "Gaussian Process Preintegration for Inertial-Aided Navigation Systems", University of Technology Sydney (Australia), 2023)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(814601809,917,'0')" target="_blank" style="color:#227967">Le Gentil, Cedric. "Gaussian Process Preintegration for Inertial-Aided Navigation Systems", University of Technology Sydney (Australia), 2023</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="110">
	    <p>
	        < 1% match (Sangay Tenzin, Alexander Rassau, Douglas Chai. "Application of Event Cameras and Neuromorphic Computing to VSLAM: A Survey", Biomimetics, 2024)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(823065411,37,'0')" target="_blank" style="color:#CB0099">Sangay Tenzin, Alexander Rassau, Douglas Chai. "Application of Event Cameras and Neuromorphic Computing to VSLAM: A Survey", Biomimetics, 2024</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="111">
	    <p>
	        < 1% match (Zhu, Alex Zihao. "Event-Based Algorithms for Geometric Computer Vision.", University of Pennsylvania, 2020)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(650980210,917,'0')" target="_blank" style="color:#006331">Zhu, Alex Zihao. "Event-Based Algorithms for Geometric Computer Vision.", University of Pennsylvania, 2020</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="112">
	    <p>
	        < 1% match (Internet from 24-Oct-2022)
	    </p>
        
        
 
	    <p><a href="https://drum.lib.umd.edu/bitstream/handle/1903/29252/Parameshwara_umd_0117E_22654.pdf?isAllowed=y&sequence=2" target="_blank" style="color:#795AB9">https://drum.lib.umd.edu/bitstream/handle/1903/29252/Parameshwara_umd_0117E_22654.pdf?isAllowed=y&sequence=2</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="113">
	    <p>
	        < 1% match (Leighton, Brenton. "Accurate 3D Reconstruction of Underwater Infrastructure Using Stereo Vision", University of Technology Sydney (Australia), 2024)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(820327731,917,'0')" target="_blank" style="color:#935F32">Leighton, Brenton. "Accurate 3D Reconstruction of Underwater Infrastructure Using Stereo Vision", University of Technology Sydney (Australia), 2024</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="114">
	    <p>
	        < 1% match (Peiyu Chen, Weipeng Guan, Feng Huang, Yihan Zhong, Weisong Wen, Li-Ta Hsu, Peng Lu. "ECMD: An Event-Centric Multisensory Driving Dataset for SLAM", IEEE Transactions on Intelligent Vehicles, 2023)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(810705720,37,'0')" target="_blank" style="color:#ce0031">Peiyu Chen, Weipeng Guan, Feng Huang, Yihan Zhong, Weisong Wen, Li-Ta Hsu, Peng Lu. "ECMD: An Event-Centric Multisensory Driving Dataset for SLAM", IEEE Transactions on Intelligent Vehicles, 2023</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="115">
	    <p>
	        < 1% match (Xiaofei Wu, Tao Liu, Caoji Li, Yuexin Ma, Yujiao Shi, Xuming He. "FastGrasp: Efficient Grasp Synthesis with Diffusion", Qeios Ltd, 2024)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(837533773,3160,'0')" target="_blank" style="color:#866712">Xiaofei Wu, Tao Liu, Caoji Li, Yuexin Ma, Yujiao Shi, Xuming He. "FastGrasp: Efficient Grasp Synthesis with Diffusion", Qeios Ltd, 2024</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="116">
	    <p>
	        < 1% match ("Computer Vision â ECCV 2016", Springer Nature, 2016)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(509998851,37,'0')" target="_blank" style="color:#63009c">"Computer Vision â ECCV 2016", Springer Nature, 2016</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="117">
	    <p>
	        < 1% match (Suraj Bijjahalli, Roberto Sabatini, Alessandro Gardi. "Advances in intelligent and autonomous navigation systems for small UAS", Progress in Aerospace Sciences, 2020)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(658591806,37,'0')" target="_blank" style="color:#A85503">Suraj Bijjahalli, Roberto Sabatini, Alessandro Gardi. "Advances in intelligent and autonomous navigation systems for small UAS", Progress in Aerospace Sciences, 2020</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="118">
	    <p>
	        < 1% match ("Computer Vision â ACCV 2020", Springer Science and Business Media LLC, 2021)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(682176773,37,'0')" target="_blank" style="color:#cc0066">"Computer Vision â ACCV 2020", Springer Science and Business Media LLC, 2021</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="119">
	    <p>
	        < 1% match (Chuanzhi Xu, Haoxian Zhou, Haodong Chen, Vera Chung, Vincent Qu. "A Survey on Event-driven 3D Reconstruction: Development under Different Categories", Qeios Ltd, 2025)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(835422237,3160,'0')" target="_blank" style="color:#21785B">Chuanzhi Xu, Haoxian Zhou, Haodong Chen, Vera Chung, Vincent Qu. "A Survey on Event-driven 3D Reconstruction: Development under Different Categories", Qeios Ltd, 2025</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="120">
	    <p>
	        < 1% match (Ling Gao, Hang Su, Daniel Gehrig, Marco Cannici, Davide Scaramuzza, Laurent Kneip. "A 5-Point Minimal Solver for Event Camera Relative Motion Estimation", 2023 IEEE/CVF International Conference on Computer Vision (ICCV), 2023)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(813494375,37,'0')" target="_blank" style="color:#336699">Ling Gao, Hang Su, Daniel Gehrig, Marco Cannici, Davide Scaramuzza, Laurent Kneip. "A 5-Point Minimal Solver for Event Camera Relative Motion Estimation", 2023 IEEE/CVF International Conference on Computer Vision (ICCV), 2023</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="121">
	    <p>
	        < 1% match (Yi-Fan Zuo, Jiaqi Yang, Jiaben Chen, Xia Wang, Yifu Wang, Laurent Kneip. "DEVO: Depth-Event Camera Visual Odometry in Challenging Conditions", 2022 International Conference on Robotics and Automation (ICRA), 2022)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(771930220,37,'0')" target="_blank" style="color:#D10A0A">Yi-Fan Zuo, Jiaqi Yang, Jiaben Chen, Xia Wang, Yifu Wang, Laurent Kneip. "DEVO: Depth-Event Camera Visual Odometry in Challenging Conditions", 2022 International Conference on Robotics and Automation (ICRA), 2022</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="122">
	    <p>
	        < 1% match (publications)
	    </p>
        
        
 
	    <p><a href="https://doi.org/10.1201/9780429468605" target="_blank" style="color:#287B28">Yigang He, Xue Qing. "Automatic Control, Mechatronics and Industrial Engineering", CRC Press, 2019</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="123">
	    <p>
	        < 1% match ("Computer Vision â ECCV 2024", Springer Science and Business Media LLC, 2025)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(826584119,37,'0')" target="_blank" style="color:blue">"Computer Vision â ECCV 2024", Springer Science and Business Media LLC, 2025</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="124">
	    <p>
	        < 1% match (Arukgoda, Janindu Sithumini. "Vector Distance Transform Maps for Autonomous Mobile Robot Navigation", University of Technology Sydney (Australia), 2023)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(814601037,917,'0')" target="_blank" style="color:brown">Arukgoda, Janindu Sithumini. "Vector Distance Transform Maps for Autonomous Mobile Robot Navigation", University of Technology Sydney (Australia), 2023</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="125">
	    <p>
	        < 1% match (publications)
	    </p>
        
        
 
	    <p><a href="https://doi.org/10.1201/9781032711157" target="_blank" style="color:#B64B01">H.L. Gururaj, Francesco Flammini, S. Srividhya, M.L. Chayadevi, Sheba Selvam. "Computer Science Engineering", CRC Press, 2024</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="126">
	    <p>
	        < 1% match (Liu, Li Yang. "Towards Observable Urban Visual SLAM", University of Technology Sydney (Australia), 2023)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(814601119,917,'0')" target="_blank" style="color:#630000">Liu, Li Yang. "Towards Observable Urban Visual SLAM", University of Technology Sydney (Australia), 2023</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="127">
	    <p>
	        < 1% match (Yuhang Ming, Xingrui Yang, Weihan Wang, Zheng Chen, Jinglun Feng, Yifan Xing, Guofeng Zhang. "Benchmarking neural radiance fields for autonomous robots: An overview", Engineering Applications of Artificial Intelligence, 2025)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(830077380,37,'0')" target="_blank" style="color:#0270B6">Yuhang Ming, Xingrui Yang, Weihan Wang, Zheng Chen, Jinglun Feng, Yifan Xing, Guofeng Zhang. "Benchmarking neural radiance fields for autonomous robots: An overview", Engineering Applications of Artificial Intelligence, 2025</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="128">
	    <p>
	        < 1% match (Ali Rida Sahili, Saifeldin Hassan, Saber Sakhrieh, Jinane Mounsef, Noel Maalouf, Bilal Arain, Tarek Taha. "A Survey of Visual SLAM Methods", IEEE Access, 2023)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(811294666,37,'0')" target="_blank" style="color:#330099">Ali Rida Sahili, Saifeldin Hassan, Saber Sakhrieh, Jinane Mounsef, Noel Maalouf, Bilal Arain, Tarek Taha. "A Survey of Visual SLAM Methods", IEEE Access, 2023</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="129">
	    <p>
	        < 1% match (Dupeng Cai, Ruoqing Li, Zhuhua Hu, Junlin Lu, Shijiang Li, Yaochi Zhao. "A comprehensive overview of core modules in visual SLAM framework", Neurocomputing, 2024)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(819608027,37,'0')" target="_blank" style="color:#227967">Dupeng Cai, Ruoqing Li, Zhuhua Hu, Junlin Lu, Shijiang Li, Yaochi Zhao. "A comprehensive overview of core modules in visual SLAM framework", Neurocomputing, 2024</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="130">
	    <p>
	        < 1% match (Huai, Zheng. "Robocentric Visual-Inertial Localization and Mapping", University of Delaware, 2023)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(812585996,917,'0')" target="_blank" style="color:#CB0099">Huai, Zheng. "Robocentric Visual-Inertial Localization and Mapping", University of Delaware, 2023</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="131">
	    <p>
	        < 1% match (publications)
	    </p>
        
        
 
	    <p><a href="https://doi.org/10.1201/9780429266737" target="_blank" style="color:#006331">John Billingsley. "Robotics and automation for improving agriculture", Burleigh Dodds Science Publishing, 2019</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="132">
	    <p>
	        < 1% match (Johnson, Jacob C.. "Continuous-Time Trajectory Estimation and Its Application to Sensor Calibration and Differentially Flat Systems", Brigham Young University, 2023)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(816128372,917,'0')" target="_blank" style="color:#795AB9">Johnson, Jacob C.. "Continuous-Time Trajectory Estimation and Its Application to Sensor Calibration and Differentially Flat Systems", Brigham Young University, 2023</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="133">
	    <p>
	        < 1% match (Joshi, Bharat. "Robust Underwater State Estimation and Mapping", University of South Carolina, 2024)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(820211909,917,'0')" target="_blank" style="color:#935F32">Joshi, Bharat. "Robust Underwater State Estimation and Mapping", University of South Carolina, 2024</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="134">
	    <p>
	        < 1% match (Kang, Peng. "Event-driven Processing and Learning with Spiking Neural Networks", Northwestern University, 2024)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(821582817,917,'0')" target="_blank" style="color:#ce0031">Kang, Peng. "Event-driven Processing and Learning with Spiking Neural Networks", Northwestern University, 2024</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="135">
	    <p>
	        < 1% match (Queen, Kendall J.. "Event-Based Perception for Ground Vehicle Control", University of Pennsylvania, 2023)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(812585080,917,'0')" target="_blank" style="color:#866712">Queen, Kendall J.. "Event-Based Perception for Ground Vehicle Control", University of Pennsylvania, 2023</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="136">
	    <p>
	        < 1% match (Shaopeng Li, Daqiao Zhang, Yong Xian, Bangjie Li, Tao Zhang, Chengliang Zhong. "Overview of deep learning application on visual SLAM", Displays, 2022)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(775772070,37,'0')" target="_blank" style="color:#63009c">Shaopeng Li, Daqiao Zhang, Yong Xian, Bangjie Li, Tao Zhang, Chengliang Zhong. "Overview of deep learning application on visual SLAM", Displays, 2022</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="137">
	    <p>
	        < 1% match (Wang, Zihao. "Synergy of Physics and Learning-Based Models in Computational Imaging and Display.", Northwestern University, 2020)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(676980038,917,'0')" target="_blank" style="color:#A85503">Wang, Zihao. "Synergy of Physics and Learning-Based Models in Computational Imaging and Display.", Northwestern University, 2020</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="138">
	    <p>
	        < 1% match (Xin Peng, Ling Gao, Yifu Wang, Laurent Kneip. "Globally-Optimal Contrast Maximisation for Event Cameras", IEEE Transactions on Pattern Analysis and Machine Intelligence, 2021)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(742657818,37,'0')" target="_blank" style="color:#cc0066">Xin Peng, Ling Gao, Yifu Wang, Laurent Kneip. "Globally-Optimal Contrast Maximisation for Event Cameras", IEEE Transactions on Pattern Analysis and Machine Intelligence, 2021</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="139">
	    <p>
	        < 1% match (YalÃ§Ä±n, Haktan. "Lie Algebra Based Augmented State EKF Design for Information Fusion in Odometry", Middle East Technical University (Turkey))
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(837675161,917,'0')" target="_blank" style="color:#21785B">YalÃ§Ä±n, Haktan. "Lie Algebra Based Augmented State EKF Design for Information Fusion in Odometry", Middle East Technical University (Turkey)</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="140">
	    <p>
	        < 1% match (Zhao, Tianxiang. "Deep Learning for Structured Data: Weak Supervision and Interpretability", The Pennsylvania State University)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(837671446,917,'0')" target="_blank" style="color:#336699">Zhao, Tianxiang. "Deep Learning for Structured Data: Weak Supervision and Interpretability", The Pennsylvania State University</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="141">
	    <p>
	        < 1% match ("Computer Vision â ECCV 2020", Springer Science and Business Media LLC, 2020)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(671178867,37,'0')" target="_blank" style="color:#D10A0A">"Computer Vision â ECCV 2020", Springer Science and Business Media LLC, 2020</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="142">
	    <p>
	        < 1% match ("RGB-D Image Analysis and Processing", Springer Science and Business Media LLC, 2019)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(643461598,37,'0')" target="_blank" style="color:#287B28">"RGB-D Image Analysis and Processing", Springer Science and Business Media LLC, 2019</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="143">
	    <p>
	        < 1% match (Geneva, Patrick F.. "Efficient, Consistent, and Persistent Visual-Inertial Navigation", University of Delaware)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(835797396,917,'0')" target="_blank" style="color:blue">Geneva, Patrick F.. "Efficient, Consistent, and Persistent Visual-Inertial Navigation", University of Delaware</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="144">
	    <p>
	        < 1% match ()
	    </p>
        
        
 
	    <p><a href="https://hdl.handle.net/20.500.11984/5986" target="_blank" style="color:brown">Etxeberria Garcia, Mikel. "Computer vision techniques for autonomous vehicles applied to urban underground railway", Mondragon Unibertsitatea. Goi Eskola Politeknikoa, 2022</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="145">
	    <p>
	        < 1% match (Shi, Yujiao. "Cross-View Image-Based Localization and Synthesis", The Australian National University (Australia), 2023)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(814600895,917,'0')" target="_blank" style="color:#B64B01">Shi, Yujiao. "Cross-View Image-Based Localization and Synthesis", The Australian National University (Australia), 2023</a>

    
    </p>
    </div>
	<div role="listitem" aria-setsize="146" aria-posinset="146">
	    <p>
	        < 1% match (Wang, Yifu. "Novel Camera Architectures for Localization and Mapping on Intelligent Mobile Platforms", The Australian National University (Australia), 2021)
	    </p>
        
        
 
	    <p><a href="javascript:openDSC(772560099,917,'0')" target="_blank" style="color:#630000">Wang, Yifu. "Novel Camera Architectures for Localization and Mapping on Intelligent Mobile Platforms", The Australian National University (Australia), 2021</a>

    
    </p>
    